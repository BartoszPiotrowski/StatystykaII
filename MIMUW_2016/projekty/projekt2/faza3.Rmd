---
title: "Faza 2"
author: "Patrycja Matys, Jan Rosa, Krzysztof Rutkowski, Magda Sobiczewska"
date: "31 maja 2016"
output: 
  html_document:
    fig_caption: yes
    toc: true
---

##Wprowadzenie
W prezentacji pokażemy w jaki sposób staraliśmy się wybrać model predykcji odsetka zachorować na raka 
piersi w danym powiecie. Korzystając z analiz dokonanych w pierwszej fazie projektu zdecydowaliśmy się
robić model wyłączenie dla kobiet. Za czynniki mogące wpływać na odsetek zachorowań wybraliśmy:
* gęstość zaludnienia
* urbanizację 
* stężenie szkodliwych substancji w powietrzu
* uciążliwe warunki pracy
* tereny zielone
* strukturę wiekową
Używaliśmy następujących metod:
* regresja liniowa
* knn z selekcją cech
* SVM 
Metoda SVM okazała się najsłabszą patrząc na MSE, więc nie będziemy jej tu omawiać.

## Przygotowanie danych
Do predykcji przygotowaliśmy dane dotyczące powiatów, gdzie zmienną objaśnianą jest znormalizowany
(przez liczbę kobiet w powiecie) odsetek kobiet chorych na raka piersi. Zaś zmiennymi objaśniającymi
są czynniki wymienione wyżej.
```{r kable}
library(knitr)
load(file = "clean_znorm.RData")
kable(head(clean.all.data))
```

##Regresja liniowa
Za pomocą regresji liniowej sprawdziliśmy na początek, które czynniki są rzeczywiście istotne. 
Wyniki testu t pokazują, że za istotne należy uznać:
*gęstość zaludnienia
*urbanizację
Przy bardziej tolerancyjnym poziomie istotności ważne również będzie stężenie szkodliwych substancji.
     

```{r, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(caret)
library(glmnet)
library(pls)
library(lars)

fit<-lm(LICZBA_ZACHOROWAN~.-TERYT-PYLY-wiek85-sredni, clean.all.data)


```

Mimo, że test t wskazał iż żaden z czynników dotyczących struktury wiekowej nie jest istotny statystycznie , to test F udowodnił iż cała ta grupa zmiennych jest istotna.
```{r, echo=FALSE}
fit1<-lm(LICZBA_ZACHOROWAN ~ GAZY+GESTOSC+URBANIZACJA+ZAGROZENIA,clean.all.data)
var.test(fit,fit1)
```
Potwierdza to również model w którym zamiast grup wiekowych użyto tylko średniego wieku mieszkańców powiatu. 
```{r, echo=FALSE}
fit2<-lm(LICZBA_ZACHOROWAN ~ GAZY +sredni+GESTOSC+URBANIZACJA+ZAGROZENIA,clean.all.data)
summary(fit2)
```
Następnie porównaliśmy metody predykcji, wielkorotnie trenując model wylosowanej z danych próbce. 
Najpierw porównano bardziej klasyczne metody metody: 
*regresje liniową z maksymalną liczbą parametrów
*regresje z liczbą parametrów wskazaną przez kryterium Akaike
*regresje grzbietową i lasso wykorzystując wszytskie parametry 
*metodę PCA wykorzystując 4 wektory PCR

Wykres przedstawia porównanie błędów przy próbkowaniach dla trzech metod, średni MSE dla wszytskich metod przedstawia tablela. 

#Wybór metody
```{r setup, include=FALSE, echo=FALSE, results='hide'}
wynik_pre_normal1<-rep(0,92)
wynik_aic1<-rep(0,92)
wynik_cv_lasso1<-rep(0,92)
wynik_cv_ridge1<-rep(0,92)
wynik_pc_ostat1<-rep(0,92)

i=1
for (i in 1:92) {
  training<-sample(1:length(clean.all.data$LICZBA_ZACHOROWAN), length(clean.all.data$LICZBA_ZACHOROWAN)*(3/4))
  clean_all_data_train<-clean.all.data[training, ]  #1/4
  clean_all_data_test<-clean.all.data[-training,]
  
  fit1_normal<-lm(LICZBA_ZACHOROWAN ~ GAZY+GESTOSC+URBANIZACJA+ZAGROZENIA+ ZIELONE + wiek0_44 + wiek45_54 + wiek55_64 + 
                    wiek65_74 + wiek75_84,data=clean_all_data_train)
  pre_normal<-predict(fit1_normal, clean_all_data_test )
  
  wynik_pre_normal1[i]<-mean((clean_all_data_test$LICZBA_ZACHOROWAN-pre_normal)^2)
  
  fit1_aic<-step(fit1_normal,data=clean_all_data_train, direction="backward")
  
  pre_aic<-predict(fit1_aic, clean_all_data_test )
  
  wynik_aic1[i]<-mean((clean_all_data_test$LICZBA_ZACHOROWAN-pre_aic)^2)
  
  
  wynik_cv_lasso<-cv.glmnet(x=as.matrix(clean_all_data_train[,-c(1,2,8,14,15)]),clean_all_data_train[,8], alpha=1)
  wynik_cv_ridge<-cv.glmnet(x=as.matrix(clean_all_data_train[,-c(1,2,8,15,14)]),clean_all_data_train[,8], alpha=0)
  
  wynik_cv_lasso_pred<-predict.cv.glmnet(object =wynik_cv_lasso,newx=as.matrix(clean_all_data_test[,-c(1,2,8,15,14)]),)
  
  wynik_cv_lasso1[i]<-mean((clean_all_data_test$LICZBA_ZACHOROWAN-wynik_cv_lasso_pred)^2)
  
  
  wynik_cv_ridge_pred<-predict.cv.glmnet(object =wynik_cv_ridge,newx=as.matrix(clean_all_data_test[,-c(1,2,8,15,14)]),)
  wynik_cv_ridge1[i]<-mean((clean_all_data_test$LICZBA_ZACHOROWAN-wynik_cv_ridge_pred)^2)
  
  wynik_pcr<-pcr(LICZBA_ZACHOROWAN ~GAZY+GESTOSC+URBANIZACJA+ZAGROZENIA+ ZIELONE + wiek0_44 + wiek45_54 + wiek55_64 + 
                   wiek65_74 + wiek75_84 , data=clean_all_data_train, ncomp=4)
  
  wynik_pcr_pred<-predict(wynik_pcr,clean_all_data_test)
  
  wynik_pc_ostat1[i]<-mean((clean_all_data_test$LICZBA_ZACHOROWAN-wynik_pcr_pred)^2)
}


```
```{r, echo=FALSE}
library(ggplot2)
a<-as.data.frame(rbind(wynik_pre_normal1,wynik_aic1,wynik_cv_lasso1,wynik_cv_ridge1,wynik_pc_ostat1))
a<-t(a)
a<-as.data.frame(a)
a$x<-c(1:92)

ggplot(data = a, aes(x = x)) +
  geom_line(aes(y = a$wynik_pre_normal1, colour = "Klasyczna regresja linowa")) +
  geom_line(aes(y = a$wynik_cv_ridge1, colour = "Regresja grzebietowa")) +
  geom_line(aes(y = a$wynik_pc_ostat1, colour = "PCA")) +
  scale_colour_manual("", 
                      breaks = c("Klasyczna regresja linowa", "Regresja grzebietowa", "PCA"),
                      values = c("red", "green", "blue")) +
  xlab("numer próbkowania") +
  scale_y_continuous("MSE", limits = c(1.0e-07,4.0e-07)) + 
  labs(title="Porównanie błędów")


```
```{r,echo=FALSE}
t<-as.data.frame(colMeans(a[,1:5]))
colnames(t) <- c("MSE")
kable(t)

```

Jak widać, za najlepsza metodę predykcji musimy na razie uznać zwykłą regresję liniową.

Wizualne przedstawienie wyników uzyskanych metodą regresji


<img src="powiaty.png" />



<img src="predykcja.png" />


Nastąpnie porównano wyniki uzyskane powyżej z tymi uzyskanymi metodą KNN

##KNN
Algorytm knn zastosowaliśmy w dwóch krokach:
1. Stworzyliśmy ranking cech korzystając z:
  + testu niezależności chi-kwadrat
  + testu korelacji rankingowej'
2. Zastosowaliśmy algorytm knn dla wybranych cech
stosując metrykę ważoną przez wagi uzyskane z selekcji atrybutów

Kod metryki:
```{r}
dist <- function(x, y, weights) {
  return(sum(weights * abs(x-y)))
}
```

Ranking cech na podstawie selekcji rank:

```{r}
load("weights_rank.RData")
kable(weights.rank)
```

Badaliśmy wyniki uzyskane z analizy 5 i 10 najlepszych sąsiadów. 
Jako metodę głosowania wśród zbioru sąsiadów wybraliśmy średnią.
Uzyskane wyniki:

```{r}
load("res_knn.RData")
kable(res)
```

Wizualne przedstawienie wyników uzyskanych metodą KNN


<img src="powiaty.png" />

<img src="predknn10.png" />


##Podsumowanie
Wyniki uzyskane metodą regresji jak i KNN są dość zbliżone, jednak lepsze uzyskujemy 
metodą knn, gdyż ma większą siłę predykcyjną, ale działa dużo wolniej i nie mamy gotowego modelu.
Z analiz selekcji atrybutów dla knn, jak i analizy regresji widać, że najistotniejszymi cechami
z punktu widzenia predykcji odsetka zachorowań są urbanizacja, gęstość zaludnienia, struktura wiekowa oraz
zanieczyszczenia.
